{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0e03eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Imports ===\n",
    "import gc\n",
    "import sys\n",
    "import os \n",
    "import warnings\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras.callbacks import EarlyStopping\n",
    "from tensorflow.python.framework.random_seed import set_random_seed\n",
    "from deep_models import CNN\n",
    "from metrics import measure_performance\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a991570c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to sample N synthetic values and augment training data\n",
    "def augment_synth_data(run_file_num, synth_amount):\n",
    "\n",
    "    synth_data = pd.read_csv(\"../data/sars/\" + file_name + \"/\" + file_name + \"_run_\" + str(run_file_num) + \"_train.csv\")\n",
    "\n",
    "    if synth_amount == \"all\":\n",
    "        return synth_data \n",
    "    \n",
    "    elif synth_amount > 0:\n",
    "        pos_sample_percentage = round(synth_amount * 0.51)  # positive label percentage\n",
    "        neg_sample_percentage = synth_amount - pos_sample_percentage  # sample 33% negative samples\n",
    "        \n",
    "        # sample for augmentation\n",
    "        positive_samples = synth_data.loc[synth_data[\"classLabel\"] == 1] \\\n",
    "            .sample(n=pos_sample_percentage, replace=False)\n",
    "        \n",
    "        negative_samples = synth_data.loc[synth_data[\"classLabel\"] == 0] \\\n",
    "            .sample(n=neg_sample_percentage, replace=False)\n",
    "        \n",
    "        # vertical concat -> row-wise\n",
    "        return pd.concat([positive_samples, negative_samples], axis=0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069ad3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === HYPERPARAMTERS ===\n",
    "_BATCH = 1\n",
    "_EPOCHS = 100\n",
    "_VERBOSITY = 0\n",
    "criterion = EarlyStopping(monitor=\"loss\", patience=5)\n",
    "NUM_SEED = 5\n",
    "NUM_RUN = 3\n",
    "input_dim = 891\n",
    "\n",
    "run_list = []\n",
    "seed_list = []\n",
    "\n",
    "# === Train Results Lists ===\n",
    "train_acc_list = []\n",
    "train_loss_curves = []\n",
    "\n",
    "# === Test Results Lists ===\n",
    "test_acc_list = []\n",
    "f1_list = []\n",
    "recall_list = []\n",
    "precision_list = []\n",
    "\n",
    "# synth data controllers, only 1 should be True at any time\n",
    "is_blended = False\n",
    "is_vae = False\n",
    "\n",
    "# synths file names\n",
    "if is_blended:\n",
    "    file_name = \"blended\"\n",
    "elif is_vae:\n",
    "    file_name = \"vae\"\n",
    "else:\n",
    "    file_name = \"orig\"\n",
    "    \n",
    "# 0, amount wanted or \"all\"\n",
    "synth_amount = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41295e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# track training time\n",
    "start_time = time.time()\n",
    "\n",
    "for run in range(1, NUM_RUN + 1):\n",
    "    print(\"######################### RUN %d #########################\" % run)\n",
    "    \n",
    "    ################\n",
    "    # DATA #\n",
    "    ################\n",
    "    \n",
    "    # === DATA SOURCES ===\n",
    "    run_training_file = \"../data/sars/orig/orig_run_\" + str(run) + \"_train.csv\"\n",
    "    run_holdout_file = \"../data/sars/orig/orig_run_\" + str(run) + \"_holdout.csv\"\n",
    "    \n",
    "    training_data = pd.read_csv(run_training_file, header=0)\n",
    "    \n",
    "    # concat training data with current augmentation\n",
    "    if is_blended or is_vae:\n",
    "        synth_data = augment_synth_data(run, synth_amount)\n",
    "        training_data = pd.concat([training_data, synth_data])\n",
    "        \n",
    "        print(f'Synth samples added: {synth_data.shape[0]}')\n",
    "        del synth_data\n",
    "    \n",
    "    # split features and labels\n",
    "    X_train = training_data.iloc[:, :-1].to_numpy()\n",
    "    X_train = X_train.reshape(-1, 1, input_dim, 1)\n",
    "    \n",
    "    y_train = training_data.iloc[:, -1].to_numpy()\n",
    "    \n",
    "    # holdout file\n",
    "    test_data = pd.read_csv(run_holdout_file, header=0)\n",
    "    X_test = test_data.iloc[:, :-1].to_numpy()\n",
    "    X_test = X_test.reshape(-1, 1, input_dim, 1)\n",
    "    \n",
    "    y_test = test_data.iloc[:, -1].to_numpy()\n",
    "    \n",
    "    print(\"Total training samples = %d\" % X_train.shape[0])\n",
    "    print(\"Total holdout samples = %d\" % y_test.shape[0])\n",
    "\n",
    "    # clean memory\n",
    "    del training_data\n",
    "    del test_data\n",
    "    del run_training_file\n",
    "    del run_holdout_file\n",
    "    gc.collect()\n",
    "    \n",
    "    ################\n",
    "    # TRAINING # \n",
    "    ################\n",
    "    \n",
    "    print('Run', '\\t', 'Seed', '\\t', 'Test Accuracy')\n",
    "\n",
    "    for seed in range(0, NUM_SEED):\n",
    "        # reproducibility\n",
    "        set_random_seed(seed)\n",
    "        np.random.seed(seed)\n",
    "        \n",
    "        run_list.append(run)\n",
    "        seed_list.append(seed)\n",
    "\n",
    "        # import and fit model\n",
    "        model = CNN(input_dim)\n",
    "\n",
    "        # train model\n",
    "        fit = model.fit(X_train, y_train, epochs=_EPOCHS, batch_size=_BATCH,\n",
    "                        shuffle=True, verbose=_VERBOSITY)\n",
    "        \n",
    "        # size = batch_size * num_seeds * num runs\n",
    "        train_loss_curves.append(fit.history['loss'])\n",
    "        train_acc_list.append(fit.history['acc'])\n",
    "\n",
    "        # get test metrics\n",
    "        accuracy, precision, recall, f1 = measure_performance(model, X_test, y_test)\n",
    "        \n",
    "        # update metric lists\n",
    "        test_acc_list.append(accuracy)\n",
    "        precision_list.append(precision)\n",
    "        recall_list.append(recall)\n",
    "        f1_list.append(f1)\n",
    "        \n",
    "        print(run, '\\t', seed, '\\t', accuracy)\n",
    "    \n",
    "    # clear data to load fresh (cache issue in notebook)\n",
    "    del X_train \n",
    "    del y_train\n",
    "    del X_test\n",
    "    del y_test\n",
    "    del model\n",
    "    del fit\n",
    "    gc.collect()\n",
    "        \n",
    "    print()\n",
    "    \n",
    "print(\"CNN took approx: %s minutes\" % round((time.time() - start_time) / 60, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1de1b8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === SAVE RESULTS ===\n",
    "# converts results lists to dataframe\n",
    "results_folder = \"../results/sars/\" + file_name\n",
    "    \n",
    "results = pd.DataFrame({'run': run_list, 'seed': seed_list, 'accuracy': test_acc_list, \n",
    "                        \"precision\": precision_list, \"recall\": recall_list, \"f1\": f1_list})\n",
    "\n",
    "# calculates the mean accuracies and the associated standard deviation\n",
    "means = results.groupby(['run'])[\"accuracy\", \"precision\", \"recall\", \"f1\"].mean()\n",
    "standard_deviations = results.groupby(['run'])[\"accuracy\", \"precision\", \"recall\", \"f1\"].std()\n",
    "\n",
    "means = means.add_prefix(\"mean_\")\n",
    "standard_deviations = standard_deviations.add_prefix(\"std_\")\n",
    "\n",
    "# creates dataframe of mean and standard deviation aggregate values\n",
    "results_summary = pd.concat([means.round(3), standard_deviations.round(3)], axis=1)\n",
    "\n",
    "# get mean of all 3 runs\n",
    "results_summary.loc[\"run_mean\"] = results_summary.mean().round(3)\n",
    "\n",
    "# Save results to File\n",
    "results.to_csv(results_folder + \"/cnn_results_\" + str(synth_amount) + \".csv\", index=False)\n",
    "results_summary.to_csv(results_folder + \"/cnn_results_summary_\" + str(synth_amount) + \".csv\")\n",
    "\n",
    "df_train_acc = pd.DataFrame(train_acc_list)\n",
    "df_train_acc.to_csv(results_folder + \"/cnn_train_acc_\" + str(synth_amount) + \".csv\", index=False)\n",
    "\n",
    "df_train_loss = pd.DataFrame(train_loss_curves)\n",
    "df_train_loss.to_csv(results_folder + \"/cnn_train_loss_\" + str(synth_amount) + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8bf4034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# arange 0-19, // by steps=5(seeds)\n",
    "train_acc_means = df_train_acc.groupby(np.arange(len(df_train_acc))//5).mean()\n",
    "train_loss_means = df_train_loss.groupby(np.arange(len(df_train_loss))//5).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f85b0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot training loss curves\n",
    "plt.title(\"Training Loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Training Loss\")\n",
    "plt.xticks(range(0, _EPOCHS+1, 10))\n",
    "\n",
    "plt.plot(train_loss_means.iloc[0, :],  label=\"Run 1\")\n",
    "plt.plot(train_loss_means.iloc[1, :], label=\"Run 2\")\n",
    "plt.plot(train_loss_means.iloc[2, :], label=\"Run 3\")\n",
    "\n",
    "plt.legend()\n",
    "plt.savefig(results_folder + \"/cnn_sars_\" + str(synth_amount) + \"_training_loss.png\")\n",
    "\n",
    "train_loss_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55437a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot training acc\n",
    "plt.title(\"Training Accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Training Accuracy\")\n",
    "plt.xticks(range(0, _EPOCHS+1, 10))\n",
    "\n",
    "plt.plot(train_acc_means.iloc[0, :], label=\"Run 1\")\n",
    "plt.plot(train_acc_means.iloc[1, :], label=\"Run 2\")\n",
    "plt.plot(train_acc_means.iloc[2, :], label=\"Run 3\")\n",
    "\n",
    "plt.legend()\n",
    "plt.savefig(results_folder + \"/cnn_sars_\" + str(synth_amount) + \"_training_acc.png\")\n",
    "\n",
    "train_acc_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3621666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot acc curves\n",
    "plt.title(\"Test Accuracy\")\n",
    "plt.xlabel(\"Seeds\")\n",
    "plt.ylabel(\"Test Accuracy\")\n",
    "plt.xticks(range(0, NUM_SEED))\n",
    "\n",
    "plt.plot(test_acc_list[0:5], \"o-\", label=\"Run 1\")\n",
    "plt.plot(test_acc_list[5:10], \"o-\", label=\"Run 2\")\n",
    "plt.plot(test_acc_list[10:15], \"o-\", label=\"Run 3\")\n",
    "\n",
    "plt.legend()\n",
    "plt.savefig(results_folder + \"/cnn_sars_\" + str(synth_amount) + \"_test_acc.png\")\n",
    "\n",
    "pd.DataFrame(test_acc_list).T"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
