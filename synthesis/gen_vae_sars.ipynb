{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0801a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from functools import partial\n",
    "import pandas as pd\n",
    "import time\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import similaritymeasures\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0c71e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loads dataframe of training (w/ classLabels), splits classes, returns two dfs\n",
    "def load_split_class(run_fold):\n",
    "    training_data = pd.read_csv(\"../data/sars/orig/orig_run_\" + str(run_fold) + \"_train.csv\")\n",
    "\n",
    "    # split classLabel column\n",
    "    X_train_fold = training_data.iloc[:, :-1]\n",
    "    y_train_fold = training_data.iloc[:, -1]\n",
    "\n",
    "    # split pos and neg\n",
    "    X_train_pos = X_train_fold.loc[y_train_fold == 1]\n",
    "    X_train_neg = X_train_fold.loc[y_train_fold == 0]\n",
    "    \n",
    "    print(\"Positive samples: %d\" % X_train_pos.shape[0])\n",
    "    print(\"Negative samples: %d\" % X_train_neg.shape[0])\n",
    "    \n",
    "    # notebook clean up\n",
    "    del X_train_fold\n",
    "    del y_train_fold\n",
    "    \n",
    "    return training_data, X_train_pos, X_train_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9722b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === VAE GRAPH CONSTRUCTION ===\n",
    "# this is based on an implementation found in Geron\n",
    "\n",
    "# layer dimensions\n",
    "n_inputs = 891\n",
    "n_hidden1 = 500\n",
    "n_hidden2 = 500\n",
    "n_hidden3 = 50  # codings\n",
    "n_hidden4 = n_hidden2\n",
    "n_hidden5 = n_hidden1\n",
    "n_outputs = n_inputs\n",
    "learning_rate = 0.001  # set learning rate\n",
    "\n",
    "# create layer initializer\n",
    "# TF1 to TF2 migration done by AF, disable eager execution for backwards compatibility\n",
    "tf.compat.v1.disable_v2_behavior()\n",
    "\n",
    "# https://devdocs.io/tensorflow~1.15/contrib/layers/variance_scaling_initializer\n",
    "initializer = tf.compat.v1.keras.initializers.VarianceScaling(scale=2.0)\n",
    "\n",
    "# define dense layer, uses elu activation function\n",
    "my_dense_layer = partial(tf.compat.v1.layers.dense,\n",
    "                         activation=tf.nn.elu,\n",
    "                         kernel_initializer=initializer)\n",
    "\n",
    "# placeholder layer for inputs\n",
    "X = tf.compat.v1.placeholder(tf.float32, [None, n_inputs])\n",
    "\n",
    "# construct graph layers\n",
    "hidden1 = my_dense_layer(X, 500)\n",
    "hidden2 = my_dense_layer(hidden1, 500)\n",
    "hidden3_mean = my_dense_layer(hidden2, 50, activation=None)\n",
    "hidden3_gamma = my_dense_layer(hidden2, 50, activation=None)\n",
    "noise = tf.random.normal(tf.shape(input=hidden3_gamma), dtype=tf.float32)\n",
    "hidden3 = hidden3_mean + tf.exp(0.5 * hidden3_gamma) * noise\n",
    "hidden4 = my_dense_layer(hidden3, 500)\n",
    "hidden5 = my_dense_layer(hidden4, 500)\n",
    "logits = my_dense_layer(hidden5, n_outputs, activation=None)\n",
    "outputs = tf.sigmoid(logits)\n",
    "\n",
    "# define cross entropy\n",
    "xentropy = tf.nn.sigmoid_cross_entropy_with_logits(labels=X, logits=logits)\n",
    "\n",
    "# define reconstruction and latent loss\n",
    "reconstruction_loss = tf.reduce_sum(input_tensor=xentropy)\n",
    "latent_loss = 0.5 * tf.reduce_sum(input_tensor=tf.exp(hidden3_gamma) + tf.square(hidden3_mean) - 1 - hidden3_gamma)\n",
    "loss = reconstruction_loss + latent_loss  # sum to produce total loss\n",
    "\n",
    "# use adam optimiser and enforce minimization of loss\n",
    "optimizer = tf.compat.v1.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "training_op = optimizer.minimize(loss)\n",
    "\n",
    "# create initializer and saver objects\n",
    "init = tf.compat.v1.global_variables_initializer()\n",
    "saver = tf.compat.v1.train.Saver()\n",
    "\n",
    "# define no. training epochs and no. of spectra to generate\n",
    "n_epochs = 10000\n",
    "pos_n_spectra = 11475 # num spectra to sample per run (matches blending)\n",
    "neg_n_spectra = 11025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2a8532f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# track training time\n",
    "start_time = time.time()\n",
    "\n",
    "for i in range(1, 4):\n",
    "    print(\"Training run \" + str(i) + \" data\")\n",
    "    \n",
    "    # load data and split pos and neg\n",
    "    all_data, X_train_pos, X_train_neg = load_split_class(i) # load run file\n",
    "    \n",
    "    # clean memory\n",
    "    del all_data\n",
    "    gc.collect()\n",
    "    \n",
    "    # num spectra to sample per run (matches blending)\n",
    "    if i == 1:\n",
    "        xVal = np.array([X_train_pos.columns[j] for j in range(n_inputs)])\n",
    "    \n",
    "    # === PRODUCE POSITIVE VAE FOLDS ===\n",
    "    with tf.compat.v1.Session() as sess:\n",
    "        init.run()\n",
    "        \n",
    "        # train for each epoch\n",
    "        for epoch in range(n_epochs):\n",
    "            \n",
    "            # train\n",
    "            sess.run(training_op, feed_dict={X: X_train_pos})\n",
    "                \n",
    "            print(\"\\r\", \"Data\", \"Pos\", \"Run\", i, \"Epoch\", epoch, end=\"\")\n",
    "            \n",
    "            # generate results\n",
    "            if epoch == n_epochs - 1:\n",
    "                codings_rnd = np.random.normal(size=[pos_n_spectra, n_hidden3])\n",
    "                outputs_val = outputs.eval(feed_dict={hidden3: codings_rnd})\n",
    "                \n",
    "                # Convert to DataFrame\n",
    "                vae_series = []\n",
    "                for spectrum in outputs_val:\n",
    "                    series = pd.Series(data=spectrum, index=xVal)\n",
    "                    vae_series.append(series)\n",
    "                    \n",
    "                pos_vae_spectra = pd.DataFrame(vae_series, dtype=\"float64\")\n",
    "                pos_vae_spectra['classLabel'] = 1\n",
    "                                \n",
    "    print()\n",
    "    \n",
    "    # make sure variables are set again\n",
    "    del X_train_pos\n",
    "    del vae_series\n",
    "    del series\n",
    "    del sess\n",
    "    gc.collect()\n",
    "    \n",
    "    # === PRODUCE NEGATIVE VAE FOLDS ===\n",
    "    with tf.compat.v1.Session() as sess:\n",
    "        init.run()\n",
    "        \n",
    "        # train for each epoch\n",
    "        for epoch in range(n_epochs):\n",
    "            \n",
    "            # train\n",
    "            sess.run(training_op, feed_dict={X: X_train_neg})\n",
    "\n",
    "            print(\"\\r\", \"Data\", \"Neg\", \"Run\", i, \"Epoch\", epoch, end=\"\")\n",
    "\n",
    "            # generate results\n",
    "            if epoch == n_epochs - 1:\n",
    "                codings_rnd = np.random.normal(size=[neg_n_spectra, n_hidden3])\n",
    "                outputs_val = outputs.eval(feed_dict={hidden3: codings_rnd})\n",
    "\n",
    "                # Convert to DataFrame\n",
    "                vae_series = []\n",
    "                for spectrum in outputs_val:\n",
    "                    series = pd.Series(data=spectrum, index=xVal)\n",
    "                    vae_series.append(series)\n",
    "\n",
    "                neg_vae_spectra = pd.DataFrame(vae_series, dtype=\"float64\")\n",
    "                neg_vae_spectra['classLabel'] = 0\n",
    "    \n",
    "    # concat blended data\n",
    "    concat_spectra = pd.concat([pos_vae_spectra, neg_vae_spectra])           \n",
    "    concat_spectra.to_csv(\"../data/sars/vae/vae_run_\" + str(i) + \"_train.csv\", index=False)\n",
    "    \n",
    "    # blank line for new run\n",
    "    print()\n",
    "    \n",
    "    # make sure variables are set again\n",
    "    del X_train_neg\n",
    "    del vae_series\n",
    "    del series\n",
    "    del sess\n",
    "    del concat_spectra\n",
    "    gc.collect()\n",
    "    \n",
    "print(\"VAE took approx: %s minutes\" % round((time.time() - start_time) / 60, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "951bf388",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfids = []\n",
    "spectral_subtractions = []\n",
    "\n",
    "# calculate coupling distance and spectral subtraction\n",
    "for i in range(1, 4):\n",
    "    real_data = pd.read_csv(\"../data/sars/orig/orig_run_\" + str(i) + \"_train.csv\")\n",
    "    synth_data = pd.read_csv(\"../data/sars/vae/vae_run_\" + str(i) + \"_train.csv\")\n",
    "    \n",
    "    # Get mean spectra of both - need to reshape for frdist\n",
    "    mean_real = real_data.iloc[:, :-1].mean().to_numpy().reshape(n_inputs, 1)\n",
    "    mean_synth = synth_data.iloc[:, :-1].mean().to_numpy().reshape(n_inputs, 1)\n",
    "    \n",
    "    dfids.append(similaritymeasures.frechet_dist(mean_real, mean_synth))\n",
    "    spectral_subtractions.append((mean_real - mean_synth).reshape(1, n_inputs))\n",
    "\n",
    "distances = pd.DataFrame({'DFIDs': dfids})\n",
    "distances.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a6ad3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "xVal = np.array([real_data.columns[j] for j in range(n_inputs)])\n",
    "subtractions = pd.DataFrame([], columns=xVal)\n",
    "\n",
    "for i in range(len(spectral_subtractions)):\n",
    "    temp = spectral_subtractions[i].reshape(n_inputs)\n",
    "    subtractions.loc[i] = pd.Series(temp, name=i, index=xVal)\n",
    "\n",
    "\n",
    "xticks = np.floor(np.linspace(0, n_inputs-1, 6)).astype(\"int\")\n",
    "\n",
    "# plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.xlabel(\"Raman Shift (cm-1)\")\n",
    "plt.ylabel(\"Variation (a.u.)\")\n",
    "plt.title(\"Spectral Subtraction of mean spectra per Run\")\n",
    "plt.xticks(xticks)\n",
    "plt.ylim([-0.05, 0.1])\n",
    "\n",
    "plt.axhline(y=0, color='k', linestyle='--')\n",
    "\n",
    "plt.plot(subtractions.iloc[0, :], label=\"Run 1\")\n",
    "plt.plot(subtractions.iloc[1, :], label=\"Run 2\")\n",
    "plt.plot(subtractions.iloc[2, :], label=\"Run 3\")\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "print(subtractions.iloc[0].min())\n",
    "print(subtractions.iloc[1].min())\n",
    "print(subtractions.iloc[2].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f43ce3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# samples\n",
    "temp_l = np.concatenate([real_data.iloc[100, :-1].values, synth_data.iloc[0, :-1].values], axis=0).reshape(2, n_inputs)\n",
    "plot_samples = pd.DataFrame(temp_l, columns=xVal.astype(np.float64))\n",
    "\n",
    "xticks = plot_samples.columns[[0, 178, 356, 534, 712, 890]].values\n",
    "\n",
    "# plot\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.xlabel(\"Raman Shift (cm-1)\")\n",
    "plt.ylabel(\"Intensity (a.u.)\")\n",
    "plt.title(\"Original vs Synthetic Raman Spectra of Positive SARS\")\n",
    "plt.xticks(xticks)\n",
    "plt.margins(0)\n",
    "plt.box(False)\n",
    "\n",
    "plt.plot(plot_samples.iloc[0, :], \"k\", label=\"Original\")\n",
    "plt.plot(plot_samples.iloc[1, :], \"y\", label=\"Synthetic\")\n",
    "     \n",
    "plt.legend()\n",
    "#plt.savefig(\"../figs/vae_orig_v_synth_positive_sample_chlorinated.jpg\", bbox_inches='tight')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
